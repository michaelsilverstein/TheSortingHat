{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Sorting Hat \n",
    "The sorting hat assigns new witches and wizards into the houses that they will join for the remainder of their stay at Hogwarts. ![Sorting Hat](https://vignette.wikia.nocookie.net/harrypotter/images/6/62/Sorting_Hat.png/revision/latest?cb=20161120072849)Presumably, the Hat uses some **prior knowledge** to inform its decision of where a student will best fit in. From a Machine Learning perspective we could view this process as a **classification** task: given some **labeled** data (for example, information about previous Hogwarts students (the **data**) and which house they belonged to (the **label/class**)) can we build a model that can **predict** which house a new student belongs to. \n",
    "\n",
    "### In order to understand the magical ways of the Hat, we will perform the following:\n",
    "1. Generate a dataset *...mmhhm...* I mean survey some previous Hogwarts students\n",
    "2. Do some basic visualization to investigate how our features separate the classes\n",
    "3. Teach a machine learning model about previous students\n",
    "4. Predict your house and visualize where you stand relative to past students!\n",
    "\n",
    "In an attempt to organize things a bit, I've put some functions in a script called [sortinghat_functions.py](https://github.com/michaelsilverstein/TheSortingHat/blob/master/sortinghat_functions.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sortinghat_functions as sh\n",
    "\n",
    "houses = ['Gryffindor', 'Hufflepuff', 'Ravenclaw', 'Slytherin']\n",
    "palette = dict(zip(houses, ['red', 'gold', 'lightblue', 'green']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Generate dataset\n",
    "The Sorting Hat itself has been endowed with years upon years of knowledge about different students. Unforunately the Hat wasn't available to send me all of its data, so we will have to generate it ourself. In my opinion, generating datasets is a valuable exercise in and of itself. A machine learning dataset consists of a few components: **samples** (in this case, students), **features** (measured characteristics), and **class labels** (in this case, the house each student belonged to). In general, a machine learning **training set** (the dataset which contains previous measurements we wish to learn from), looks like this:\n",
    "\n",
    "| Sample | Feature 1 | $\\cdot\\cdot\\cdot$ | Feature N | Class |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| Sample$_1$ | Observation$_{1,1}$ | $\\cdot\\cdot\\cdot$ | Observation$_{1,N}$ | Class$_1$ |\n",
    "|  $\\cdot\\cdot\\cdot$ |  $\\cdot\\cdot\\cdot$ | $\\cdot\\cdot\\cdot$ | $\\cdot\\cdot\\cdot$| $\\cdot\\cdot\\cdot$ |\n",
    "| Sample$_M$ | Observation$_{M,1}$ | $\\cdot\\cdot\\cdot$ | Observation$_{M,N}$ | Class$_M$ |\n",
    "\n",
    "Now, we have to imagine that the Sorting Hat has gathered information on all sorts of features, some of which will have more discriminatory power than others. For example, below is the height distribution of the students from each house. \n",
    "```python\n",
    "\"\"\"Generate height example\"\"\"\n",
    "# Assume same mean height, standard deviation, and class size for each house\n",
    "mean_height = 5*12+7/12\n",
    "std = 5\n",
    "n = 20\n",
    "# The seed for a random process establishes where the process \"starts from\". This allows us to \n",
    "# re\n",
    "random_seed = 1\n",
    "\n",
    "data = sh.generate_feature(mean_height, std, n, houses, random_seed)\n",
    "df = pd.DataFrame(data, columns=['height', 'house'])\n",
    "g = sns.FacetGrid(df, hue='house', aspect=2.5)\n",
    "g.map(sns.kdeplot, 'height', shade=True).add_legend(title='House')\n",
    "plt.xlabel('Height (in)')\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "```\n",
    "![Height distribution](figures/height_dist.png) \n",
    "\n",
    "As we can see it doesn't seem like this feature (height) does not provide much discriminatory power between the different classes (as in, if all we knew about the students was their height we would have very little ability to distinguish which ones belonged to which house). Below we will generate data for some more features we believe the Hat may have observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
